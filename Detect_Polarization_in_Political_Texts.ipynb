{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKH8pDIoM49GzaTbrV7WzN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gthivaios/Bank-Greek-Tweets-Sentiment-Analysis/blob/main/Detect_Polarization_in_Political_Texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Interact with ChatGPT for Text Understanding\n"
      ],
      "metadata": {
        "id": "LYKb4isW7hPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is associated to a how-to guide that gives a simple introduction to using Large Language Models for text analysis in the social sciences.\n",
        "\n",
        "The notebook offers the code for the example of analyzing the level of polarization in a given political text, but can easily be adapted for your particular text analysis project."
      ],
      "metadata": {
        "id": "qUjOxNkEGYnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Signing up for API access\n",
        "\n",
        "The first step is to sign up to API access with OpenAI. This can be done on platform.openai.com.\n",
        "\n",
        "You will receive an API key to be used below."
      ],
      "metadata": {
        "id": "Qdlh2C8CPfgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Installing and loading the relevant libraries\n",
        "\n",
        "We first need to install and import the relevant libraries: the pandas package for general data processing, and the openai package for interacting with the OpenAI API."
      ],
      "metadata": {
        "id": "vIFxmc3gRd6X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS2xUoXj7Lgn"
      },
      "outputs": [],
      "source": [
        "#Install the libraries\n",
        "!pip install pandas\n",
        "!pip install openai==0.28\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Call the libraries\n",
        "import os\n",
        "import time\n",
        "import openai\n",
        "import tiktoken\n",
        "import nltk\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk.data\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "d4jKuQYBR1dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the API key. See the how-to guide for furhter instructions\n",
        "openai.api_key = \"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\"\n",
        "#We define which model to use throughout\n",
        "MODEL = 'gpt-3.5-turbo-16k'\n",
        "max_tokens = 120\n",
        "WAIT_TIME = 20 #"
      ],
      "metadata": {
        "id": "h2tq61QsSDbP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now call the OpenAI API. For instance, we can ask ChatGPT-4 a question:"
      ],
      "metadata": {
        "id": "ns0vyPPNSUC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the API\n",
        "response = openai.ChatCompletion.create(\n",
        "  model = MODEL, #Which model to use\n",
        "  temperature=0.2, #How random is the answer\n",
        "  max_tokens=120, #How long can the reply be\n",
        "  messages=[\n",
        "    {\"role\": \"user\",\n",
        "    \"content\": \"What is polarization in political texts?\"}]\n",
        ")\n",
        "result = ''\n",
        "for choice in response.choices:\n",
        "    result += choice.message.content\n",
        "print(f\"Model answer: '{result}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC1Aeu1TSUsQ",
        "outputId": "f694a5bf-548a-4f89-b35d-dcd5d25c0cc7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model answer: 'Polarization in political texts refers to the division or separation of opinions, beliefs, or ideologies into extreme or opposing positions. It occurs when political texts, such as speeches, articles, or social media posts, emphasize and reinforce differences between groups or individuals, leading to a more polarized political climate. Polarization can be seen in the language, tone, and content of political texts, as they often aim to appeal to specific audiences or promote a particular agenda. This can result in the amplification of conflicts, the creation of echo chambers, and the erosion of common ground or compromise in political discourse.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Loading and preparing your data\n",
        "\n",
        "The next step is to load and prepare the data that we want to analyze. We will load the data into a Pandas dataframe to allow easy processing.\n",
        "\n",
        "The details of how to open your particular data depends on the structure and format of the data. Pandas offers ways of opening a range of file formats, including CSV and Excel files. You may wish to refer to the Pandas documentation for more details."
      ],
      "metadata": {
        "id": "UYV__e8ZSsY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtWvrMt0p2je",
        "outputId": "044146b6-76a2-4bed-d01f-6108e1ced54a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading data from textfiles\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the folder path where the text files are located\n",
        "folder_path = '/content/gdrive/MyDrive/test/'\n",
        "\n",
        "# Use glob to get a list of all *.txt files in the folder\n",
        "txt_files = glob.glob(folder_path + '/*.txt')\n"
      ],
      "metadata": {
        "id": "yWs49g4dS5qG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking the texts\n",
        "Unlike other NLP methods, not much preprocessing is needed. However, LLMs are only able to process texts that are smaller than their \"context window\". If our texts are longer than the context window of our model, we have to either split the texts into several smaller chunks and analyze them part by part, or simply truncate the text (not recommended).\n",
        "\n",
        "The details depend on the model you use and the amount for data. we will use the standard 16K GPT-3.5 model and chunk the text into smaller pieces. If your text is short, such as a tweet, this function will do nothing."
      ],
      "metadata": {
        "id": "7YXgzOnBQzXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_chunks(text, max_tokens):\n",
        "\n",
        "    #Code the text in gpt coding and calculate the number of tokens\n",
        "    encoding = tiktoken.encoding_for_model(MODEL)\n",
        "    nrtokens = len(encoding.encode(text))\n",
        "\n",
        "    if nrtokens < max_tokens:\n",
        "        return [text]\n",
        "\n",
        "    #how many chunks to split it into?\n",
        "    num_chunks = np.ceil(nrtokens / max_tokens)\n",
        "\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Calculate the number of words per chunk\n",
        "    words_per_chunk = len(text.split()) // num_chunks\n",
        "\n",
        "    # Initialize variables\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    word_counter = 0\n",
        "    # Iterate through each sentence\n",
        "    for sentence in sentences:\n",
        "        # Add the sentence to the current chunk\n",
        "        current_chunk.append(sentence)\n",
        "        word_counter += len(sentence.split())\n",
        "\n",
        "        # Check if the current chunk has reached the desired number of words\n",
        "        if word_counter >= words_per_chunk:\n",
        "            # Add the current chunk to the list of chunks\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            word_counter = 0\n",
        "            # Reset the current chunk\n",
        "            current_chunk = []\n",
        "\n",
        "    # Add the remaining sentences as the last chunk\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "bV9ekAQQcK24"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file(file_path, max_tokens):\n",
        "  with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "    return split_text_into_chunks(text, max_tokens)"
      ],
      "metadata": {
        "id": "xUT40lbf6U8b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Prompt engineering\n",
        "\n",
        "The next step is to formulate a first instructions for analyzing the text. The prompts will be a result of an iterative process through which you develop a formulation of the concept that you wish to capture."
      ],
      "metadata": {
        "id": "n9od68a-nzRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"\"\"Your task is to evaluate the level of polarization in a political text. Polarization is considered an important feature of political systems. Although usually seen as a negative trait, it is important to recognise that a certain degree of polarization is reasonable and perhaps necessary. Political polarization represents the intensity of binary, opposing political ideologies and their respective party identities. Below are some critical features of a polarizing discourse:\n",
        "1) Polarization occurs when a discourse promotes strong partisan or ideological divisions. This discourse promotes a representation of politics in dichotomous and binary terms, where society is divided into two major camps. A multitude of differences and contradictions are reduced to a single division. The remaining differences are downplayed.\n",
        "2) The two political and ideological positions that this discourse constructs are presented as incompatible, and the political views and attitudes of citizens tend to diverge and cluster around these two opposing ideological positions. It creates a powerful and irreconcilable opposition between two camps, each challenging or even denying the legitimacy of the other. The political opponent becomes an enemy.\n",
        "3) This discourse limits pluralism and fosters fanaticism. It results in the marginalization of intermediate or alternative views from the public sphere and, correspondingly, the squeezing and even the exclusion of smaller parties.\n",
        "4) A discourse that increases polarization perceives and describes politics through the “us” vs. “them” distinction. There is no midpoint, everyone is asked to choose sides.\n",
        "5) A discourse of polarization has a strong emotional dimension.\n",
        "6) Polarizing discourse, in order to gain depth, often invokes deeply rooted social identities or social divisions that last over time and emphasizes opposing pairs of concepts and values (for example, modernization-tradition, progress-conservatism, workers-capitalists, right-left)\n",
        "\n",
        "You should give the text a numeric grade between 0 and 1.\n",
        "1. A speech in this category includes strong expressions of all of the polarization elements,  but either does not use them consistently or tempers them by including non-populist elements. The text may have a romanticized notion of the people and the idea of a unified popular will, but it avoids bellicose language or any particular enemy.\n",
        "0. A speech in this category uses few if any populist elements.\n",
        "[Answer with a number in the 0-1 range, followed by a semi-colon, and then a brief motivation. For instance: \"1.23; The text shows many elements of a populist text.\" Do not use quotation marks.]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h8fxUTTuoCrX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Calling the LLM and analyzing the results\n",
        "## 5.1 Call the LLM\n",
        "\n",
        "We will now write simple functions for calling the API and carry out our analysis request. We will also need to handle possible errors returned from the API."
      ],
      "metadata": {
        "id": "sMwSG6T1Fv5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import time\n",
        "#import numpy as np\n",
        "#import openai\n",
        "#from nltk.tokenize import sent_tokenize\n",
        "\n",
        "#openai.api_key = 'your-api-key'\n",
        "max_chunk_size = 4000\n",
        "\n",
        "def call_openai_api(input_text):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            max_tokens=150,\n",
        "            temperature=0.2,\n",
        "            messages=[{\"role\": \"system\", \"content\": prompt_text},\n",
        "                      {\"role\": \"user\", \"content\": input_text}]\n",
        "        )\n",
        "        return [choice.message['content'] for choice in response.choices]\n",
        "    except openai.error.RateLimitError as e:\n",
        "        print(\"Rate limit reached. Retrying in 20 seconds...\")\n",
        "        time.sleep(21)\n",
        "        return call_openai_api(input_text)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return None\n",
        "\n",
        "generated_responses = []\n",
        "\n",
        "for file_path in txt_files:\n",
        "    chunk_texts = process_file(file_path, max_chunk_size)\n",
        "    for input_text in chunk_texts:\n",
        "        success = False\n",
        "        while not success:\n",
        "            generated_responses_chunk = call_openai_api(input_text)\n",
        "            if generated_responses_chunk is not None:\n",
        "                generated_responses.extend(generated_responses_chunk)\n",
        "                success = True\n",
        "\n",
        "print(\"Generated responses:\", generated_responses)\n",
        "\n",
        "# Calculate average response length\n",
        "average_response_length = np.mean([len(response.split()) for response in generated_responses])\n",
        "print(\"Average response length:\", average_response_length)"
      ],
      "metadata": {
        "id": "QEKyrhnIacWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Example result\n",
        "We can now look at some examples of the result from the analysis and the associated motivation."
      ],
      "metadata": {
        "id": "3HlFup6zGH5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average response length: 0.3; The text does not strongly promote strong partisan or ideological divisions. It does mention the opposition and contrasts their actions with those of the New Democracy party, but it does not use bellicose language or present the opposition as an enemy. The text focuses more on the achievements and future plans of the New Democracy party rather than creating a strong opposition between two camps."
      ],
      "metadata": {
        "id": "AsQCZbDUGLJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_response_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "SPLS2qh1WYEd",
        "outputId": "94f36a8b-e43b-4536-90ac-f0874bf0a541"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3; The text does not strongly promote strong partisan or ideological divisions. It does mention the opposition and contrasts their actions with those of the New Democracy party, but it does not use bellicose language or present the opposition as an enemy. The text focuses more on the achievements and future plans of the New Democracy party rather than creating a strong opposition between two camps.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}